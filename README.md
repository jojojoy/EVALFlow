# EVALFlow

![CI](https://github.com/jojojoy/EVALFlow/actions/workflows/ci.yml/badge.svg)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

> **EVALFlow** is a lightweight **LLM evaluation & regression monitoring toolkit** in Python.  
> It helps you run reproducible benchmarks, compute metrics, and generate reports (HTML/Markdown) for model comparison.

---

## âœ¨ Features

- ğŸ“Š **Metrics**: ROUGE-L, Accuracy, BLEU (with smoothing)  
- ğŸ¤– **Providers**:
  - DummyProvider (offline demo)
  - OpenAIProvider (`pip install -e .[openai]`, requires `OPENAI_API_KEY`)
- ğŸ“‘ **Reporters**: HTML + Markdown reports (auto-generated)
- âš™ï¸ **Config-driven**: run tasks via YAML configs (`configs/`)
- ğŸ”„ **Regression Monitoring**: compare runs against baselines
- âœ… **CI Ready**: tested via GitHub Actions (`pytest`)

---

## ğŸš€ Quickstart

### 1. Install
```bash
git clone https://github.com/jojojoy/EVALFlow.git
cd EVALFlow
python -m venv .venv
source .venv/bin/activate   # Windows: .venv\Scripts\Activate.ps1
pip install -e .[dev]

---

## ğŸ“Š Example Output

After running:

```bash
evalflow run --config configs/summarization.yaml --out runs/demo